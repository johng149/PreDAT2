{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_seq = torch.tensor([1,3,2,4,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_vertices = 10\n",
    "vocab_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_matrix = torch.tensor(\n",
    "    [\n",
    "        [0, 0.9, 0.04, 0, 0.06, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
    "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
    "        [0, 0, 0, 0, 0, 0.5, 0.5, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    ]\n",
    ")\n",
    "emission_matrix = torch.ones(num_vertices, vocab_size) / vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfs(target_seq, transition_matrix, emission_matrix, seq, prob, storage):\n",
    "    if len(seq) == len(target_seq):\n",
    "        storage.append((seq, prob))\n",
    "        return\n",
    "    if len(seq) == 0:\n",
    "        start_prob = emission_matrix[0][target_seq[0]]\n",
    "        dfs(target_seq, transition_matrix, emission_matrix, [0], start_prob, storage)\n",
    "    else:\n",
    "        next_candidates = transition_matrix[seq[-1]]\n",
    "        for i, p in enumerate(next_candidates):\n",
    "            if p > 0:\n",
    "                new_prob = prob * p * emission_matrix[i][target_seq[len(seq)]]\n",
    "                dfs(target_seq, transition_matrix, emission_matrix, seq + [i], new_prob, storage)\n",
    "                \n",
    "def max_prob_path(storage):\n",
    "    max_prob = 0\n",
    "    max_seq = []\n",
    "    for seq, prob in storage:\n",
    "        if prob > max_prob:\n",
    "            max_prob = prob\n",
    "            max_seq = seq\n",
    "    return max_seq, max_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs(target_seq, transition_matrix, emission_matrix, [], 1, storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_prob = sum([prob for seq, prob in storage])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 1, 6, 7, 9], tensor(0.0003))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_prob_path(storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfs_lynchpin(target_seq, transition_matrix, emission_matrix, seq, prob, storage, assignments=None):\n",
    "    if len(seq) == len(target_seq):\n",
    "        storage.append((seq, prob))\n",
    "        return\n",
    "    if len(seq) == 0:\n",
    "        start_prob = emission_matrix[0][target_seq[0]]\n",
    "        dfs_lynchpin(target_seq, transition_matrix, emission_matrix, [0], start_prob, storage, assignments)\n",
    "    else:\n",
    "        next_candidates = transition_matrix[seq[-1]]\n",
    "        current_assignment = -1 if assignments is None else assignments[len(seq)]\n",
    "        for i, p in enumerate(next_candidates):\n",
    "            if p > 0 and (current_assignment == -1 or current_assignment == i):\n",
    "                new_prob = prob * p * emission_matrix[i][target_seq[len(seq)]]\n",
    "                dfs_lynchpin(\n",
    "                    target_seq, \n",
    "                    transition_matrix, \n",
    "                    emission_matrix, \n",
    "                    seq + [i], \n",
    "                    new_prob, \n",
    "                    storage,\n",
    "                    assignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "assignments = torch.tensor([-1, 4, -1, 7, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_lynchpin(target_seq, transition_matrix, emission_matrix, [], 1, storage, assignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([0, 4, 5, 7, 9], tensor(9.6000e-06)), ([0, 4, 6, 7, 9], tensor(9.6000e-06))]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_lynchpin_prob = sum([prob for seq, prob in storage])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_gather(vectors, indices):\n",
    "    \"\"\"\n",
    "    Gathers (batched) vectors according to indices.\n",
    "    Arguments:\n",
    "        vectors: Tensor[N, L, D]\n",
    "        indices: Tensor[N, K] or Tensor[N]\n",
    "    Returns:\n",
    "        Tensor[N, K, D] or Tensor[N, D]\n",
    "    \"\"\"\n",
    "    N, L, D = vectors.shape\n",
    "    squeeze = False\n",
    "    if indices.ndim == 1:\n",
    "        squeeze = True\n",
    "        indices = indices.unsqueeze(-1)\n",
    "    N2, K = indices.shape\n",
    "    assert N == N2\n",
    "    indices = einops.repeat(indices, \"N K -> N K D\", D=D)\n",
    "    out = torch.gather(vectors, dim=1, index=indices)\n",
    "    if squeeze:\n",
    "        out = out.squeeze(1)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logsumexp(x: Tensor, dim: int) -> Tensor:\n",
    "    # Solving nan issue when x contains -inf\n",
    "    # See https://github.com/pytorch/pytorch/issues/31829\n",
    "    # https://github.com/thu-coai/DA-Transformer/blob/main/fs_plugins/custom_ops/dag_loss.py\n",
    "    m, _ = x.max(dim=dim, keepdim=True)\n",
    "    mask = m == -float(\"inf\")\n",
    "    m = m.detach()\n",
    "    s = (x - m.masked_fill_(mask, 0)).exp_().sum(dim=dim, keepdim=True)\n",
    "    return s.masked_fill_(mask, 1).log_() + m.masked_fill_(mask, -float(\"inf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dag_loss_raw(targets, transition_matrix, emission_probs):\n",
    "    \"\"\"\n",
    "    Calculates the directed acyclic graph (DAG) loss given the targets, transition matrix, and emission probabilities.\n",
    "    It returns the dynamic programming table of which one of the entries is the DAG loss.\n",
    "\n",
    "    Args:\n",
    "        targets (torch.Tensor): The target sequence of shape (batch_size, m).\n",
    "        transition_matrix (torch.Tensor): The transition matrix of shape (batch_size, l, l).\n",
    "        emission_probs (torch.Tensor): The emission probabilities of shape (batch_size, l, vocab_size).\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The DAG loss of shape (batch_size, m, l).\n",
    "    \"\"\"\n",
    "    batch_size, m = targets.shape\n",
    "    _, l, vocab_size = emission_probs.shape\n",
    "    dp = torch.ones((batch_size, m, l), device=transition_matrix.device)\n",
    "    dp[dp == 1] = -float(\"inf\")\n",
    "    initial_probs = torch.gather(\n",
    "        emission_probs, dim=2, index=targets[:, 0].unsqueeze(1).unsqueeze(2)\n",
    "    )\n",
    "    dp[:, 0, 0] = initial_probs.squeeze(2).squeeze(1)\n",
    "    # assumes that transition_matrix and emission_probs are already in log space\n",
    "    # also we need to tranpose emission_probs so it is vocab_size x l\n",
    "    # so the vector gather works\n",
    "    emission_probs = emission_probs.transpose(1, 2)\n",
    "    for i in range(1, m):\n",
    "        dp[:, i, :] = vector_gather(emission_probs, targets[:, i]) + (\n",
    "            (\n",
    "                logsumexp(\n",
    "                    dp[:, i - 1, :].unsqueeze(1).transpose(1, 2) + transition_matrix,\n",
    "                    dim=1,\n",
    "                )\n",
    "            ).squeeze(1)\n",
    "        )\n",
    "    return dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_matrix = torch.log(transition_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "emission_matrix = torch.log(emission_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_matrix = transition_matrix.unsqueeze(0)\n",
    "emission_matrix = emission_matrix.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_seq = target_seq.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\Projects\\ML\\PreDAT2\\.venv\\lib\\site-packages\\transformers\\utils\\hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dp = dag_loss_raw(target_seq, transition_matrix, emission_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2.0000e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 3.6000e-02, 1.6000e-03, 0.0000e+00, 2.4000e-03,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2000e-04, 0.0000e+00,\n",
       "          2.4000e-04, 7.4400e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 1.5360e-03, 6.4000e-05, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2000e-04]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00032000005012378097"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(total_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0003199999628122896"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(torch.exp(dp[0][-1][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_dp_slice_for_spans(\n",
    "    dp_slice: Tensor, target_span_indices: Tensor, iteration: int\n",
    ") -> Tensor:\n",
    "    \"\"\"\n",
    "    @param dp: (batch_size, num_vertices, 1) tensor of scores that is being consiered\n",
    "        by the current iteration (position in target sequence)\n",
    "    @param target_span_indices: (batch_size, seq_len) tensor of indices, if element\n",
    "        is non-negative, it represents that position in target sequence span otherwise\n",
    "        it is negative\n",
    "    @param iteration: int, the current iteration in the target sequence\n",
    "\n",
    "    @return dp_slice: (batch_size, num_vertices, 1) tensor of scores that guarantees\n",
    "        that all paths considered go through the vertex specified by the target_span_indices\n",
    "        if it is non-negative, otherwise scores of paths are not changed to -inf\n",
    "    \"\"\"\n",
    "    res = dp_slice\n",
    "    res = res.squeeze(2)\n",
    "\n",
    "    # here we cannot simply use this res to update the dp table,\n",
    "    # because this res update assumes that all paths are allowed,\n",
    "    # however, if we are at a span, only the path that passes\n",
    "    # through the span's specified vertex is allowed\n",
    "    # to do this, we set the probability of all other vertices\n",
    "    # to -inf, so that they are not considered in the max operation\n",
    "    # in the next step. This guarantees in the next step, we only\n",
    "    # consider paths that pass through the span's specified vertex\n",
    "    curr_span_status = target_span_indices[:, iteration - 1]\n",
    "    in_span = curr_span_status >= 0\n",
    "\n",
    "    # we need to do a masked_fill here for curr_span_status, because\n",
    "    # we use gather to get the current probability of the span vertex\n",
    "    # in res, and gather doesn't support negative indices.\n",
    "    # this also means the corresponding probability might not be useful\n",
    "    # because if it is not a span then we don't enforce that paths\n",
    "    # must pass through the span's vertex. We account for this later\n",
    "    curr_span_status = curr_span_status.masked_fill(~in_span, 0).unsqueeze(1)\n",
    "\n",
    "    selection = res.gather(1, curr_span_status)\n",
    "\n",
    "    masked = torch.full_like(res, -float(\"inf\"))\n",
    "    masked.scatter_(1, curr_span_status, selection)\n",
    "\n",
    "    in_span = in_span.unsqueeze(-1)\n",
    "    in_span = in_span.expand_as(res)\n",
    "\n",
    "    res = torch.where(in_span, masked, res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dag_loss_raw_lynchpin(targets, transition_matrix, emission_probs, assignments):\n",
    "    \"\"\"\n",
    "    Calculates the directed acyclic graph (DAG) loss given the targets, transition matrix, and emission probabilities.\n",
    "    It returns the dynamic programming table of which one of the entries is the DAG loss.\n",
    "\n",
    "    Args:\n",
    "        targets (torch.Tensor): The target sequence of shape (batch_size, m).\n",
    "        transition_matrix (torch.Tensor): The transition matrix of shape (batch_size, l, l).\n",
    "        emission_probs (torch.Tensor): The emission probabilities of shape (batch_size, l, vocab_size).\n",
    "        assignments (torch.Tensor): The assignments of shape (batch_size, m).\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The DAG loss of shape (batch_size, m, l).\n",
    "        \n",
    "    The assignments tensor is a tensor of shape (batch_size, m) where each element is an integer from 0 to l-1.\n",
    "    If the element is -1, then the corresponding element in the target sequence is free to be any of the l vertices.\n",
    "    Otherwise, at that position in the target sequence, the vertex must be the one specified by the assignment.\n",
    "    \"\"\"\n",
    "    batch_size, m = targets.shape\n",
    "    _, l, vocab_size = emission_probs.shape\n",
    "    dp = torch.ones((batch_size, m, l), device=transition_matrix.device)\n",
    "    dp[dp == 1] = -float(\"inf\")\n",
    "    initial_probs = torch.gather(\n",
    "        emission_probs, dim=2, index=targets[:, 0].unsqueeze(1).unsqueeze(2)\n",
    "    )\n",
    "    dp[:, 0, 0] = initial_probs.squeeze(2).squeeze(1)\n",
    "    # assumes that transition_matrix and emission_probs are already in log space\n",
    "    # also we need to tranpose emission_probs so it is vocab_size x l\n",
    "    # so the vector gather works\n",
    "    emission_probs = emission_probs.transpose(1, 2)\n",
    "    for i in range(1, m):\n",
    "        # before proceeding, we need to check the previous iteration's dp values\n",
    "        # to see if that it agrees with the assignments, if not, we need to adjust\n",
    "        # the dp values accordingly\n",
    "        prev_dp = dp[:, i - 1, :].unsqueeze(1).transpose(-1, -2)\n",
    "        prev_dp = correct_dp_slice_for_spans(prev_dp, assignments, i)\n",
    "        dp[:, i - 1, :] = prev_dp\n",
    "        dp[:, i, :] = vector_gather(emission_probs, targets[:, i]) + (\n",
    "            (\n",
    "                logsumexp(\n",
    "                    dp[:, i - 1, :].unsqueeze(1).transpose(1, 2) + transition_matrix,\n",
    "                    dim=1,\n",
    "                )\n",
    "            ).squeeze(1)\n",
    "        )\n",
    "    return dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "assignments = assignments.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp2 = dag_loss_raw_lynchpin(target_seq, transition_matrix, emission_matrix, assignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ -1.6094,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,\n",
       "              -inf,     -inf,     -inf],\n",
       "         [    -inf,     -inf,     -inf,     -inf,  -6.0323,     -inf,     -inf,\n",
       "              -inf,     -inf,     -inf],\n",
       "         [    -inf,     -inf,     -inf,     -inf,     -inf,  -8.3349,  -8.3349,\n",
       "              -inf,     -inf,     -inf],\n",
       "         [    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,\n",
       "           -9.2512,     -inf,     -inf],\n",
       "         [    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,\n",
       "              -inf,     -inf, -10.8606]]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.920000067912042e-05"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(total_lynchpin_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.920001523103565e-05"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(torch.exp(dp2[0][-1][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
